{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "007dbd6a-212c-41dc-8784-0c3f6700ca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "from typing import Iterable, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbd46454-4f48-4918-8152-fa1f46375401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c2cce09-d501-4836-99fc-857b5e1cdfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc1ca3ad-822d-4461-b531-9c79791bce35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"DEVICE: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8763a82-152f-486b-99c3-82377f2329d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Transformer as TestTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0824480-a045-4411-a8ae-0339bd24663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
    "multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a8d0827-e789-4857-bb0e-22cfb2bea4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_LANGUAGE = 'de'\n",
    "TGT_LANGUAGE = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1e4f9e9-4117-4ecd-8b29-5cf236edb7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_transform = {}\n",
    "vocab_transform = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5444ee8b-072f-43a4-9547-a055deb56096",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64cbb79f-5475-4722-8624-50216639eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to yield list of tokens\n",
    "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language_index[language]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60993cc7-07e5-4a61-9f78-c356263d5733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d44174a0-a91e-4e4e-9526-7f54f4f1d26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    # Training data Iterator\n",
    "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    # Create torchtext's Vocab object\n",
    "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
    "                                                    min_freq=1,\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d41442ca-5db5-4f04-9491-ca4ae85452ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set ``UNK_IDX`` as the default index. This index is returned when the token is not found.\n",
    "# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "  vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5505ea5-3fd7-4bb2-a464-19f1ec08023f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9b1eb612f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bc24ce6-82b7-4f8c-9b15-c304e4aa3acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC_VOCAB_SIZE: 19214, TGT_VOCAB_SIZE: 10837\n"
     ]
    }
   ],
   "source": [
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "print(f\"SRC_VOCAB_SIZE: {SRC_VOCAB_SIZE}, TGT_VOCAB_SIZE: {TGT_VOCAB_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d498f988-2b24-4a82-ada3-be96472b3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab66d6f1-d7a1-4e1b-b9a2-1cff7aa5ef07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer: Transformer(\n",
      "  (encoder): Encoder(\n",
      "    (positional_embedding): PositionalEmbedding(\n",
      "      (embedding_layer): Embedding(19214, 512)\n",
      "      (position_embedding_layer): PositionEncoding()\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (encoder_layers): ModuleList(\n",
      "      (0-2): 3 x EncoderLayer(\n",
      "        (attention): GlobalSelfAttention(\n",
      "          (multi_head_attention): MultiHeadAttention(\n",
      "            (q_linear_projection_func): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (k_linear_projection_func): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (v_linear_projection_func): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (attention_projection_func): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (attention): ScaledDotProductAttention()\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (ff): FeedForwardLayer(\n",
      "          (ff): PositionWiseFeedForward(\n",
      "            (linear_1_func): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (relu_func): ReLU()\n",
      "            (linear_2_func): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (ff_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (ff_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (positional_embedding): PositionalEmbedding(\n",
      "      (embedding_layer): Embedding(19214, 512)\n",
      "      (position_embedding_layer): PositionEncoding()\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (decoder_layers): ModuleList(\n",
      "      (0-2): 3 x DecoderLayer(\n",
      "        (causal_self_attention): CausalSelfAttention(\n",
      "          (multi_head_attention): MultiHeadAttention(\n",
      "            (q_linear_projection_func): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (k_linear_projection_func): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (v_linear_projection_func): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (attention_projection_func): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (attention): ScaledDotProductAttention()\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (cross_attention): CrossAttention(\n",
      "          (multi_head_attention): MultiHeadAttention(\n",
      "            (q_linear_projection_func): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (k_linear_projection_func): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (v_linear_projection_func): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (attention_projection_func): Linear(in_features=512, out_features=512, bias=False)\n",
      "            (attention): ScaledDotProductAttention()\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (ff): FeedForwardLayer(\n",
      "          (ff): PositionWiseFeedForward(\n",
      "            (linear_1_func): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (relu_func): ReLU()\n",
      "            (linear_2_func): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (ff_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (ff_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_layer): Linear(in_features=512, out_features=10837, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "transformer = TestTransformer(\n",
    "    SRC_VOCAB_SIZE,\n",
    "    TGT_VOCAB_SIZE,\n",
    "    EMB_SIZE,\n",
    "    NHEAD,\n",
    "    FFN_HID_DIM,\n",
    "    0.1,\n",
    "    NUM_ENCODER_LAYERS,\n",
    "    NUM_DECODER_LAYERS\n",
    ")\n",
    "print(f\"transformer: {transformer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b845b4fc-1380-468f-8841-d1535b1833ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "252e1b42-c21a-4c76-8585-23727213ef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transformer.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "856e8d0f-2d91-4a40-9c30-6905cfeb3a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "369a5266-43dd-416e-9f94-e897674e847c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manman/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d69d5507-5c07-4c22-99ed-1a8811f12bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21aaa7c5-2131-449a-b6f8-cd1a248932ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eae56399-8317-4170-9475-ada010cd6aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
    "                                               vocab_transform[ln], #Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9834c361-8072-4de5-a0d0-d21575c4fcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to collate data samples into batch tensors\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edae9f5-6c83-42dd-95c2-a3d1322ca29c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
